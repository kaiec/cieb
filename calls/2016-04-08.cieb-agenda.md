LD4PE CompIndex Editorial Board - Telecon 9 (Fri 2016-04-08)

* Agenda:   https://github.com/ld4pe/cieb/blob/master/calls/2016-04-08.cieb-agenda.md
* Previous: https://github.com/ld4pe/cieb/blob/master/calls/2016-03-11.cieb-notes.md
* Expected: Tom, Sean, Stuart, Debbie. Regrets: Magnus, Kai.
* Time:     0600 SFO / 0900 NYC / 1500 BER
* WebEx:    https://meetings.webex.com/collabs/meetings/join?uuid=M35W1OR0MAMVGXZ89PSPRN8HJH-JV0D
  * Meeting number: 196 227 489 (meeting does not require a password)
  * Audio Connection +1-415-655-0001 US TOLL
  * Access code: 190 952 037
  * Support: https://meetings.webex.com/collabs/#/support
  * Meeting password: This meeting does not require a password.

======================================================================
CIEB calls - Fridays at the usual time (see above)

* http://doodle.com/poll/np47qhu7tc6k46q6

  * April 22 
  * May 13 
  * June 3    - regrets: Debbie
  * June 24   - regrets: Debbie

* September/October - one or two final calls

======================================================================
Location of the the competency index as published in WordPress

* http://explore.dublincore.net/linked-data-learning-resources/
  This is where latest "published" version of the competency index may be found

* On the call, Stuart will clarify whether this supersedes the older page
  http://explore.dublincore.net/comp-index/

======================================================================
Review of Competency Index

-- 2016-01-20. https://docs.google.com/document/d/1i1k5kZLWncb3dJozb61SQiRS7hljUAox-gEXs4gHs7o
   This Google doc has been "frozen".  
   
-- 2016-04-25? Next version will depend on decisions outlined below.

-- https://github.com/ld4pe/cieb/blob/master/calls/2016-03-11.resource_representation_jan2016.pdf
   Overview of how many resources are currently described under each category.

----------------------------------------------------------------------
A Fundamentals of Resource Description Framework 

*  Identity in RDF 
  * Knows that anything can be named with URIs, such as agents, places, events, artifacts, and concepts
  * __Understands that a "real-world" thing may need to be named with a URI separate from the URI for
    a description of that thing__
  * __Recognizes that URI names are "owned" by the respective owners of the Internet domain name.__

*  RDF data model 
  * Knows the subject-predicate-object component structure of a triple 
  * Understands that URIs and literals denote things in the world ("resources") real, imagined, or conceptual
  * Understands the difference between literals and non-literal resources
  * Understands that resources are declared members (instances) of classes using the property rdf:type
  * Understands the use of datatypes and language tags with literals
  * Understands blank nodes and their uses
  * Understands that QNames define shorthand prefixes for long URIs 
    * Uses prefixes for URIs in RDF specifications and data
  * Understands the concept of the named graph
  * Articulates differences between the RDF abstract data model and the XML and relational models
  * Understands the use of RDF Schema to create and interpret RDF vocabularies
  * Understands the RDF abstract data model as a directed labeled graph
  * Knows graphic conventions for depicting RDF-based models
    * Can use graphing or modeling software to share those models with others
  * __NEEDED? Mr DC (Wellywood Staplegun) competency: difference between LD and the Internet of Things__
  * __NEEDED? Mr DC (Wellywood Staplegun) competency: difference between relational DB and triplestore.__

*  Related data models
  * __GAP: competency about difference between RDF and object-oriented class models__
  * Grasps essential differences between schemas for syntactic validation (e.g., XML) and for inferencing (RDF Schema)
  * Differentiates hierarchical document models (eg, XML) and graph models (RDF)

*  RDF serialization
  * Distinguishes the RDF abstract data model and concrete serializations of RDF data
    * Expresses data in serializations such as RDF/XML, N-Triples, Turtle, N3, Trig, JSON-LD, and RDFa
  * Understands RDF serializations as interchangeable encodings of a given set of triples (RDF graph)
    * Uses tools to convert RDF data between different serializations

A Fundamentals of Linked Data
*  Web technology
  * __NEED: Definition?__
  * __NEED: Competency about HTML (needed for viewing and for RDFa)__
  * __NEED: Competency about HTTP__
  * __NEED: Competency about REST__
  * __NEED: Competency about URI schemes__

  * Sean: __Understands that RDFa is a way to express RDF data within HTML, in a way
    that is machine-readable, and by reusing the existing human-readable data
    in the document.__
    * Sean: __Uses RDFa to publish Linked Data in HTML, XHTML, XML, and SVG documents.__
    * Sean: __Uses appropriate tools to edit, visualize, and debug HTML+RDFa code.__
  * Sean: __Understands that markups such as RDFa can be used to generate better search
    listings and improve visibility on the Web.__
    * Sean: __Uses RDFa to express Rich Snippets or schema.org, so that web pages will be
      displayed in an enhanced format on all major search engines.__
    * Sean: __Uses Open Graph Protocol to express concepts that are contained in web
      pages (e.g., people, places, events, movies and recipes).__
  * Sean: __Employs JSON-LD in order to use Linked Data in Web-based programming
    environments, to build interoperable Web services, and to store Linked Data
    in JSON-based storage engines.__

*  Linked data principles
  * Tom: __Knows Tim Berners-Lee's principles of Linked Data: use URIs to name things, use HTTP URIs 
    that can be resolved to useful information, and create links to URIs of other things.__
  * Tom: __Knows the "five stars" of Open Data: put data on the Web, preferably in a structured and 
    preferably non-proprietary format, using URIs to name things, and linking to other data.__

*  Linked Data architectures and services
  * __NEED: Definition?__
  * Sean:  __Understands Linked Data query processing is a special case of federated
    query processing with special challenges caused by the highly distributed
    structure and evolving nature of Linked Data__
    * Sean: __Generates candidate execution plans and selects one of these plans for
      actual execution__
    * Sean: __Considers criteria including: minimizing the overall execution time,
      minimizing response time, minimizing network traffic, or maximizing the
      degree of result completeness__
  * Sean: __Understands that a URI is relevant for a given query if looking up this URI
    gives us data that contributes to the query result.__
    * Sean: __Given a Linked Data query, determines a set of URIs to look up (i.e.,
      source selection) which works towards selecting all relevant URIs and only
      relevant URIs__
    * Sean: __Knows that advantages and disadvantages of both index-based and live
      exploration strategies for source selection.__
  * Sean: __Understands that there are integrated and separated approaches to query
    execution.__
    * Sean: __Knows that integrated execution combines the data retrieval and result
      construction process into one phase.__
  * Sean: __Knows that separated execution approaches clearly separate data retrieval
    from result construction by two consecutive phases.__

__[Tom notes that this category is associated with a relatively 
[low number of described resources](https://github.com/ld4pe/cieb/blob/master/calls/2016-03-11.resource_representation_jan2016.pdf) 
and wonders whether the competencies above reflect the content of those categories 
and, if so, whether this category should be a candidate for deletion.]__

*  Linked Data policies and best practices
  * Knows the primary organizations related to Linked Data standardization
    * Participates in developing standards and best practice with relevant organizations such as W3C
*  Non-RDF Linked Data
    * Tom: __Candidate for deletion pending response from Marjie Hlava?__

A RDF vocabularies and application profiles
*  Finding RDF-based vocabularies
  * Retrieves and accesses RDF data from the "open Web"
    * __Tom notes that this competency seems out of place.__
    * Tom: __[competency about using LOV]__

*  Designing RDF-based vocabularies
  * Sean: __Understands that OWL (Web Ontology Language) is a more expressive option
    for data modeling and reasoning than RDFS.__
    * Sean: __Understands that OWL allows one to describe data in terms of set operations
      (e.g. unionOf).__
    * Sean: __Understands that OWL allows one to define equivalences across datasets
      (e.g. sameAs).__
    * Sean: __Understands that OWL allows one to restrict property values (e.g.
      allValesFrom).__
    * Sean: __Uses OWL annotations (e.g., owl:versionInfo, owl:backwardsCompatibleWith,
      owl:deprecatedProperty) to express relationships between different
      ontologies.__
  * Sean: __Understands that Simple Knowledge Organization System (SKOS) is a simpler
    alternative to RDFS and OWL suitable for tasks such as describing
    controlled vocabularies.__
  * Sean: __Uses classes to describe concepts (loosely defined as "ideas"), concept
    collections, and concept schemes.__
    * __Uses properties (e.g., skos:exactMatch, skos: broader, and skos:narrower)
      to map between separate vocabularies.  [or put under "Mapping RDF vocabularies"?]__

  * Uses RDF Schema to express semantic relationships within a vocabulary
    * Correctly uses sub-class relationships in support of inference
    * Correctly uses sub-property relationships in support of inference
  * Knows the naming conventions for RDF properties and classes
  * Reuses published properties and classes where available
    * Uses portals and registries to find existing RDF-based vocabularies
  * Coins namespace URIs, as needed, for any new properties and classes required
    * Drafts a policy for coining URIs for properties and classes
    * Chooses "hash"- or "slash"-based URI patterns based on requirements

*  Maintaining RDF vocabularies
  * Understands policy options for persistence guarantees
    * Can draft a persistence policy

*  Versioning RDF vocabularies
  * Knows technical options for the form, content, and granularity of versions
    * Can express and justify a versioning policy

*  Publishing RDF vocabularies
  * Understands the typical publication formats for RDF vocabularies and their relative advantages
  * Understands the purpose of publishing RDF vocabularies in multiple formats using content negotiation

*  Mapping RDF vocabularies
  * __GAP: competencies along the lines: SKOS mapping properties, other predicates, controversial owl:sameAs__

*  RDF application profiles
  * Identifies real-world entities in an application domain as requirements for RDF classes
  * Identifies resource attributes and relationships between domain entities as requirements for RDF properties
  * Investigates how others have modeled the same or similar application domains
    * Communicates a domain model with words and diagrams
    * Participates in the social process of developing application profiles

A Creating and transforming RDF Data
*  Managing identifiers (URIs)
  * __NEED: competency about namespace policies__
  * __NEED: competency about redirect services such as purl.org__
  * Sean: __Understands the principle of persistence, i.e. that a URI is permanently
    assigned to a particular resource, is stable, and does not change or vanish
    over time.__
    * Sean: __Avoids including version numbers and status information in URIs__
    * Sean: __Exercises caution when using auto-increment for minting new URIs__
    * Sean: __Avoids using query strings in URIs__
    * Sean: __Avoids using organization names in URIs__
    * Sean: __Avoids using file extensions in URIs__

  * Tom thinks the points above are too detailed and suggests:
    __Understands trade-offs between "opaque" URIs and URIs using
    version numbers, dates, file extensions, query strings or other 
    obsoletable context__

  * Sean: __Understands the principle of dereferencability, i.e. a user agent can make
    a request to a URI over the Internet and receive a meaningful response
    back.__
    * Sean: __Ensures that if the user agent is a Web browser, then what comes back is a
      human readable HTML document__
    * Sean: __Ensures that If the user agent is an RDF client then RDF is returned from
      the same URI.__

  * Tom: __[Re: the above: There is already a point about content negotiation
    under "publishing RDF vocabularies" -- Maybe that is enough?]__

  * Sean: __Understands that URIs should be unambiguous, meaning that there should be
    no confusion between identifiers for Web documents and identifiers for
    other resources__
    * Sean: __Implements 303 URIs for real-world resources to avoid ambiguity.__
  * Tom: __[suggests a competency similar to the above under "Identity in RDF"]__

  * Sean: __In order to create and manage URIs, one should be the owner of the
    respective Internet domain and/or have administrator’s rights on it__
    * Sean: __Uses a dedicated service independent of the data originator (e.g. Dublin
      Core and purl.org)__
    * Sean: __Is aware of the existence of any national URI policies or dedicated
      services for persistence.__
  * Tom: __[suggests a competency similar to the above under "Identity in RDF"]__

*  Creating RDF data
  * Structures data using blank nodes where appropriate 
  * Generates RDF data from non-RDF sources

*  Versioning RDF data
  * __GAP: competency contrasting "periodic numbered releases versus more incremental approaches__

*  RDF data provenance
  * Kai: __see ACTION__
  * Tom: __[is this is about "provenance of RDF data" - or "expressing provenance of a resource" in RDF?]__

*  Cleaning and reconciling RDF data
  * Cleans a dataset by finding and correcting errors, removing duplicates and unwanted data

*  Mapping and enriching RDF data

  * Sean: __Is aware that the W3C has defined a direct mapping from relational
    representation to an RDF representation of data.__
    * Sean: __Uses the direct mapping to materialize RDF graphs or define virtual graphs,
      which can be queried by SPARQL or traversed by an RDF graph API.__
  * Sean: __Is aware of the companion specification, the R2RML mapping language, that
    allows the creation of customized mapping from relational data to RDF.__
    * Sean: __Uses a default mapping generated by R2RML for further customization.__

  * Uses available resources for named entity recognition, extraction, and reconciliation

----------------------------------------------------------------------
A Interacting with RDF Data

*  Finding RDF Data
  * Retrieves and accesses RDF data from the "open Web"
  * Uses relevant resources to discover existing Linked Data datasets
  * Monitors and updates lists which report the status of SPARQL endpoints
  * Uses available vocabularies for dataset description to support their discovery
  * Registers datasets with relevant services for discovery   
  * Sean: __Downloads whole datasets provided as one big file (i.e., a "data dump")__

*  Programming RDF Data
  * Tom: __[proposes calling this: Programmatic processing of RDF Data, unless this 
    change would be too disruptive]__
  * __NEED: Definition?__
  * Sean: __[see also Proposal under "Web technology"]__

  * Sean: __Understands that working with very large datasets requires distributed
    storage (e.g., Hadoop) and processing (MapReduce). [Sean: Should this be 
    under "Storing RDF data"?]__
  * Sean: __Uses a programming language (e.g., Javascript) to request data from a
    Linked Data service.__
    * Sean: __Use the jQuery function “ajax” to call a query against an endpoint. 
  * Sean: __Understands that the RDFLib library defines a plugin interface for parsers,
    stores, and serializers that other packages can use.__
    * Sean: __Imports available common namespaces (e.g., RDFS, OWL, XSD, SKOS) directly
      from rdflib.__
    * Sean: __Uses appropriate packages (e.g sparql-client, SPARQLWrapper) for SPARQL
      implementation with RDFLib.__
  * Sean: __Understands that the primary interface RDFLib exposes to work with RDF is a
    “Graph”.__
  * Sean: __Selects the appropriate type of “Graph” from the RDFLib graph Module:
    Graph, Conjunctive Graph, Quoted Graph, and Dataset.__
    * Sean: __Knows that the class Graphs supports the python “in” operator, as well as
      iteration and some operations like union, difference and intersection.__
    * Sean: __Uses the class ConjunctiveGraph to form an aggregation of all the named
      graphs in a store.__
    * Sean: __Uses the class Quoted Graph to implement N3 formulae for scenarios such as
      implication and other such processing.__

*  Querying RDF Data
  * Understands that a SPARQL query matches an RDF graph against a pattern of triples with fixed and variable values
  * Understands the basic syntax of a SPARQL query
    * Uses angle brackets for delimiting URIs
    * Uses question marks for indicating variables
    * Uses PREFIX for base URIs
  * Formulates advanced queries on data containing blank nodes
  * Demonstrates a working knowledge of the forms and uses of SPARQL result sets
    * Uses the SELECT clause to identify the variables to appear in a table of query results
    * Uses the WHERE clause provide the graph pattern to match against the graph data
    * Uses variables in SELECT and WHERE clauses to yield a table of results
    * Uses ASK for a True/False test for a match to a query pattern
    * Uses DESCRIBE to extract a single graph containing RDF data about resources
    * Uses CONSTRUCT to extract and transform results into a single RDF graph specified by a graph template
  * Understands how to combine and filter graph patterns using operators such as UNION, OPTIONAL, FILTER, and MINUS
    * Uses UNION to formulate queries with multiple possible graph patterns
    * Uses OPTIONAL to formulate queries to return the values of optional variables when available
    * Uses FILTER to formulates queries that eliminate solutions from a result set
    * Uses NOT EXISTS to limit whether a given graph pattern exists in the data
    * Uses MINUS to remove matches from a result based on the evaluation of two patterns
    * Uses NOT IN to restrict a variable to not being in a given set of values
  * Understands the major SPARQL result set modifiers, e.g., to limit or sort results, or to return distinct results only once
    * Uses ORDER BY to define ordering conditions by variable, function call, or expression
    * Uses DISTINCT to ensure solutions in the sequence are unique
    * Uses OFFSET to control where the solutions processed start in the overall sequence of solutions
    * Uses LIMIT to restrict the number of solutions processed for query results
    * Uses projection to transforms a solution sequence into one involving only a subset of the variables 
  * Understands the use of SPARQL functions and operators
    * Uses the regular expression (regex()) function for string matching
    * Uses aggregates to apply expressions over groups of solutions (GROUP BY, COUNT, SUM, AVG, MIN) for partitioning results, evaluating projections, and filtering
    * Uses the lang() function to return the language tag of an RDF literal
    * Uses the langMatches() function to match a language tag against a language range
    * Uses the xsd:decimal(expn) function to convert an expression to an integer
    * Uses the GROUP BY clause to transforms a result set so that only one row will appear for each unique set of grouping variables 
    * Uses the HAVING clause to apply a filter to the result set after grouping    
  * Differentiates between a Default Graph and a Named Graph, and formulates queries using the GRAPH clause
    * Formulates advanced queries using FROM NAMED and GRAPH on local data
    * Formulate advanced queries using FROM NAMED on remote data
  * Formulate advanced queries using subqueries
  * Uses a temporary variable to extend a query
  * Understands the role of Property Paths and how they are formed by combining predicates with regular expression-like operators
  * Understands the concept of Federated Search
    * Formulates advanced queries on a remote SPARQL endpoint using the SERVICE directive
    * Uses federated query to query over a local graph store and one or more other SPARQL endpoints
    * Pulls data from a different SPARQL endpoints in one single query using the SERVICE directive
  * Converts/manipulates SPARQL query outputs (RDF-XML, JSON) to the exact format required by a third party tools and APIs
  * Formulates queries using FROM with URLs and local files
  * Reads and understands high-level descriptions of the classes and properties of a dataset in order to write queries 
  * Uses available tools, servers, and endpoints to issue queries against a dataset 
    * Execute SPARQL queries using the Jena ARQ command-line utility
    * Queries multiple local data files using ARQ
    * Uses ARQ to evaluate queries on local data
    * Uses Fuseki server to evaluate queries on a dataset
    * Queries multiple data files using Fuseki
    * Accesses DBPedia's SNORQL/SPARQL endpoint and issues simple queries     
*  Visualizing RDF Data
  * Uses publicly available tools to visualize data
    * Uses Google FusionTables to create maps and charts
  * Distills results taken from large datasets so that visualizations are human-friendly
  * Converts/manipulates SPARQL query outputs (RDF-XML, JSON) to the exact format required by a third party tools and APIs 
*  Reasoning over RDF data

  * Sean: __Understands that the different “flavors” of OWL trade off expressive
    modeling power for computational efficiency when performing reasoning.__
    * Sean: __Knows that previous versions of OWL (OWL/Lite, OWL/DL, and OWL/Full)
      mentioned in older documents have been superseded by newer OWL 2 flavors.__
    * Sean: __Uses OWL 2/Full to take advantage of all available constructs when
      reasoning performance is not a concern.__
    * Sean: __Uses OWL 2/EL when there are a large number of classes and properties
      linked together through complicated relationships and an automated reasoner
      will be used to draw out further relationships.__
    * Sean: __Uses OWL 2/QL for querying large amounts of instance data that sit in
      traditional relational databases.__
    * Sean: __Uses OWL 2/RL for applications which are built on a business rules engine
      using complicated class relationships.__

  * Understands the principles and practice of inferencing
    * Uses common entailment regimes and understands their uses
  * Understands the role of formally declared domains and ranges for inferencing
  * Understands how reasoning can be used for integrating diverse datasets

*  Assessing RDF data quality
  * __Candidate for deletion?__

*  RDF Data analytics
  * Sean: __[is this about using RDF data for analytics (Data Science)?]__
  * Uses available ontology browsing tools to explore the ontologies used in a particular dataset 

*  Manipulating RDF Data
  * Knows the SPARQL 1.1 Update language for updating, creating, and removing RDF graphs in a Graph Store
    * Uses INSERT/DELETE to update triples
    * Uses a CONSTRUCT query to preview changes before executing an INSERT/DELETE operation
  * Knows the SPARQL 1.1 Graph Store HTTP protocol for updating graphs on a Web server (in "RESTful" style)
    * Uses GET to retrieve triples from a default graph or a named graph
    * Uses PUT to insert set of triples into a new graph (or replace an existing graph)
    * Uses DELETE to remove a graph
    * Uses POST to add triples to an existing graph
    * Uses proper syntax to request specific media types, such as Turtle
  * Understands the difference between SQL query language (which operates on database tables) and SPARQL (which operates on RDF graphs)

A Creating Linked Data applications
*  Storing RDF data
  * Sean: __Understands that database systems designed for the storage and retrieval of
    RDF data  are called "triple stores"__
    * Sean: __Knows that some popular RDF stores include Sesame, Jena, Redland, and
      OpenLink Virtuoso.__
  * Sean: __Understands that data can be copied into a centralized repository to create
    a data warehouse which can then be queried.__

*  Linked Data application architecture
  * Sean: __NEED Definition to distinguish from "Linked Data architecture and services"?__
  * Sean: __[see Proposal under "Web technology"]__
*  Linked Data mashups
  * __Candidate for deletion?__

======================================================================
ACTIONS

__ACTION__: Tom to respond Mike Lauruhn: We do not think that it is appropriate
to classify competencies by proficiency level (Beginner, etc).  However, we
_do_ think it is appropriate to classify particular resources by level.

__ACTION__: Stuart to write to Diane re: cleaning data.

__ACTION__: Stuart to ping Seth and Ruben.

__ACTION__: Tom to propose RDF.rb competencies to run by Tom Johnson (see also above)

__ACTION__: Tom to ask John Kunze to propose a competency 
related to management of ARKs.

__ACTION__: Kai to write provenance competency about differentiating simple
approach and representing the chain.

__ACTION__: Tom to propose competencies related to SKOS.

__ACTION__: Tom to ask Adam Rabinowitz to propose one competency related to 
period identifiers for temporally indexed data, with a link to PERIODO work.

======================================================================
Other potential gaps

* Schema.org?
* Microdata?

======================================================================
Other potential contacts (Sean) 

On the February 19 call, we discussed the idea of writing to the some of the
authors of resources indexed by LD4PE, saying (roughly) "we indexed your video
X using the competencies Y and Z" and asking them to comment on the Competency
Index.

See: https://github.com/ld4pe/cieb/blob/master/calls/2016-03-11.resource_creators_v2.docx

* David Sherlock, DBpedia: Visualizing Linked Data, https://www.youtube.com/watch?v=qAVGpb8KMpk
* Soren Auer, Linked Data Tutorial, http://www.slideshare.net/soeren1611/linked-data-tutorial-presentation-955375?related=1
* Marek Obitko, Ontologies and Semantic Web, http://www.obitko.com/tutorials/ontologies-semantic-web/ontologies.html
* Pedro Szekely, Linked Data & Cultural Heritage, http://www.slideshare.net/szeke/2015-0205aackarma
* Juan Sequeda, Introduction to Linked Data, http://www.slideshare.net/juansequeda/introduction-to-linked-data-2341398?related=2
* Aidan Hogan, Jared McGinnis, Introduction to Linked Data: Background Technologies and Standards, Motivating Application Scenario, http://videolectures.net/eswc2013_hogan_mcginnis_linked_data/
* Olaf Hartig, Linked Data Query Processing: Introduction, http://dsg.uwaterloo.ca/LDQTut2013/LDQTut2013_1.pdf
* Ani Da, From Excel file to RDF with links to DBpedia and Europeana, https://www.youtube.com/watch?v=XdpzmGxA33U
* Chris Bizer, Richard Cyganiak, Tom Heath, How to Publish Linked Data on the Web, http://wifo5-03.informatik.uni-mannheim.de/bizer/pub/LinkedDataTutorial/
* ISA Programme of the European Commission, Cookbook for Translating Relational Data Models to RDF Schemas, http://ec.europa.eu/isa/documents/cookbook-for-rdf-schemas-v2.pdf
* LinkedDataTools.com, Tutorial 1: Introducing Graph Data, http://www.linkeddatatools.com/introducing-rdf

======================================================================
RDF Cataloging Tool (Sean) - time permitting...

-- See the tool at 
   http://explore.dublincore.net/rdf/lrmi/#/resource

-- Sean's "Instructions" draft
   https://docs.google.com/document/d/1KKDP6QZSLcfKdVhB3kOvUFqdbPq3k1WNDb_pITC0bTg/edit?usp=sharing
   https://github.com/ld4pe/cieb/blob/master/calls/2016-03-11.cataloging_tool_instructions.docx

